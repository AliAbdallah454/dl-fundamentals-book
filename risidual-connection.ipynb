{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c64b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env-test/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/env-test/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /Users/aliabdallah/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60192808"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet34, resnet152\n",
    "\n",
    "resnet = resnet152(pretrained=True)\n",
    "\n",
    "numel_list = []\n",
    "for p in resnet.parameters():\n",
    "    numel_list.append(p.numel())\n",
    "\n",
    "sum(numel_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aebe2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e336834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "            \n",
    "    # He et al. (ResNet paper) explicitly designed the block so that:\n",
    "\n",
    "    # Setting convolution weights ≈ 0\n",
    "    # → The block behaves like identity\n",
    "\n",
    "    # If ReLU is inside the residual path early, identity mapping is impossible.\n",
    "\n",
    "\n",
    "    # Resnets protects the network from harmful depth\n",
    "    # If dF(x)/dx is bad or small the gradient can still flow through identity => stable learning\n",
    "\n",
    "    def __init__(self, n_input, n_output, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "        self.conv1 = nn.Conv2d(n_input, n_output, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(n_output)\n",
    "        # There is no self.relu1 because the residual should be as linear as possible and the ReLU destorys information\n",
    "\n",
    "        self.conv2 = nn.Conv2d(n_output, n_output, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(n_output)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.conv1(inp)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample:\n",
    "            inp = self.downsample(inp)\n",
    "        return x + inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, padding=3, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.comp1 = nn.Sequential(\n",
    "            ResidualBlock(64, 64, 2),\n",
    "            ResidualBlock(64, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "        )\n",
    "\n",
    "        down1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "\n",
    "        self.comp2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128, 2, downsample=down1),\n",
    "            ResidualBlock(128, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )\n",
    "\n",
    "        down2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "\n",
    "        self.comp3 = nn.Sequential(\n",
    "            ResidualBlock(128, 256, 2, down2),\n",
    "            *[ResidualBlock(256, 256) for _ in range(5)]            \n",
    "        )\n",
    "\n",
    "        down3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "\n",
    "        self.comp4 = nn.Sequential(\n",
    "            ResidualBlock(256, 512, 2, down3),\n",
    "            ResidualBlock(512, 512),\n",
    "            ResidualBlock(512, 512)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc1 = nn.Linear(512, 1000) # 1000 -> number of classes\n",
    "\n",
    "    def forward(self, inp):\n",
    "\n",
    "        x = self.conv_block1(inp)\n",
    "        x = self.comp1(x)\n",
    "        x = self.comp2(x)\n",
    "        x = self.comp3(x)\n",
    "        x = self.comp4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
